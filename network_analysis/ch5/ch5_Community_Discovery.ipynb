{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0YvtQmRB2k0"
   },
   "source": [
    "<span>\n",
    "<b>Python version:</b>  3.7<br/>\n",
    "<b>CDlib version:</b>  0.1.10<br/>\n",
    "<b>Last update:</b> 25/11/2021\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-rHaM3QB2k1"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2jwfhbxB2k2"
   },
   "source": [
    "<a id='top'></a>\n",
    "# *Chapter 5: Community Discovery*\n",
    "\n",
    "In this notebook are introduced the main steps for the extraction and topological analysis of communities.\n",
    "\n",
    "**Note:** this notebook is purposely not 100% comprehensive, it only discusses the basic things you need to get started. For all the details, algorithm/methods/evaluation facilities available in ``CDlib``, please refer to the official [documentation](https://cdlib.readthedocs.io) and the dedicated notebook appendix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMiyNhMBB2k2"
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Community Discovery Workflow](#workflow)\n",
    "    1. [Graph Creation](#graph)\n",
    "    2. [Community Discovery algorithm(s) selection and configuration ](#model)\n",
    "    3. [Clustering Evaluation (Fitness functions)](#fitness)\n",
    "    4. [Clustering Evaluation (Comparison)](#comparison)\n",
    "    5. [Community/Statistics Visualization](#visualization)\n",
    "    5. [Qualitative evaluation](#qualitative)\n",
    "    7. [Ground Truth evaluation](#gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wCLEiJi6B2k3"
   },
   "outputs": [],
   "source": [
    "import cdlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfNBsS_QB2k3"
   },
   "source": [
    "<a id='workflow'></a>\n",
    "## Community Discovery Workflow ([to top](#top))\n",
    "\n",
    "The standard workflow can be summarized as:\n",
    "- Network Creation\n",
    "- Community Discovery algorithm(s) selection and configuration\n",
    "- Clustering(s) evaluation (Fitness functions)\n",
    "- Clustering(s) evaluation (Comparisons)\n",
    "- Community/Statistics Visualization\n",
    "\n",
    "In this section we will observe how to templating such workflow applying two classic network clustering algorithms: Label Propagation and Leiden.\n",
    "All analysis will be performed using ``CDlib``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HuFNMpZ1B2k4"
   },
   "source": [
    "<a id=\"graph\"></a>\n",
    "### Graph object creation ([to top](#top))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJiEuTLYB2k4"
   },
   "source": [
    "As a first step we need to define the network topology that will be used as playground to study diffusive phenomena.\n",
    "\n",
    "``CDlib`` natively supports both [``networkx``](https://networkx.github.io) and [``igraph``](https://igraph.org/python/) data structures.\n",
    "\n",
    "In our examples, for the sake of simplicity, we will use ``networkx`` undirected graphs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7kAofMrB2k5"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def read_net(filename):\n",
    "    g = nx.Graph()\n",
    "    with open(filename) as f:\n",
    "        f.readline()\n",
    "        for l in f:\n",
    "            l = l.split(\",\")\n",
    "            g.add_edge(l[0], l[1])\n",
    "    return g\n",
    "\n",
    "# Game of Thrones Season \n",
    "season = 1\n",
    "g = read_net(f'asioaf/got-s{season}-edges.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQKpHrkLB2k5"
   },
   "source": [
    "<a id=\"model\"></a>\n",
    "### Community Discovery algorithm(s) selection and configuration ([to top](#top))\n",
    "\n",
    "After having defined the graph, we can select the algorithm(s) to partition it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7sXVtZEKB2k6"
   },
   "outputs": [],
   "source": [
    "from cdlib import algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CGsMniVSB2k6"
   },
   "outputs": [],
   "source": [
    "lp_coms = algorithms.label_propagation(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cfRSj58HJvPB"
   },
   "outputs": [],
   "source": [
    "lp_coms.communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nzERh4NvB2k6"
   },
   "outputs": [],
   "source": [
    "leiden_coms = algorithms.leiden(g) # improvement on Louvain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZxB8P3tB2k7"
   },
   "source": [
    "All Community Discovery algorithms generate as result an object that implements a concrete instance of the ``Clustering`` datatype.\n",
    "\n",
    "In particular, both Louvain and Label Propagation returns a ``NodeClustering`` object having the following propterties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AqW_vnwDB2k7"
   },
   "outputs": [],
   "source": [
    "leiden_coms.method_name # Clustering algorithm name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6uFJqY0OB2k8"
   },
   "outputs": [],
   "source": [
    "leiden_coms.method_parameters # Clustering parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GnG-1SUpB2k8"
   },
   "outputs": [],
   "source": [
    "leiden_coms.communities # Identified Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XkLJ-GCCB2k8"
   },
   "outputs": [],
   "source": [
    "leiden_coms.overlap # Wehter the clustering is overlapping or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vXW2QzAqB2k8"
   },
   "outputs": [],
   "source": [
    "leiden_coms.node_coverage # Percentage of nodes covered by the clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eNJM7YMuB2k9"
   },
   "source": [
    "Moreover, ``Clustering`` object allow also for the generation of a JSON representation of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbF8X97sB2k9"
   },
   "outputs": [],
   "source": [
    "leiden_coms.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AE9lEn74B2k_"
   },
   "source": [
    "<a id=\"comparison\"></a>\n",
    "### Clustering Evaluation (Comparison) ([to top](#top))\n",
    "\n",
    "When multiple clustering have been computed on a same network it is useful to measure their resemblance.\n",
    "\n",
    "``CDlib`` allows to do so by exposing several clustering resemblance scores, each one of them tailored to support specific kind of network clusterings (crisp/partition, complete/partial node coverage).\n",
    "\n",
    "As for the fitness functions, resemblance scores can be instantiated at the community level as well as at the library level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7oY96PrnB2k_"
   },
   "outputs": [],
   "source": [
    "leiden_coms.normalized_mutual_information(lp_coms,  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8vqJJMlDB2k_"
   },
   "outputs": [],
   "source": [
    "cdlib.evaluation.normalized_mutual_information(leiden_coms, lp_coms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ju1W7JU9B2k_"
   },
   "source": [
    "## Exercise: visualize the network in which colors correspond to communities\n",
    "\n",
    "- try several algorithms\n",
    "- compare the results\n",
    "\n",
    "Note: you can also do it with `cdlib` (python 3.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "siY9SQETB2lB"
   },
   "source": [
    "<a id=\"qualitative\"></a>\n",
    "### Qualitative evaluation ([to top](#top))\n",
    "\n",
    "Another way to validate a clustering is to analyse the purity of each community w.r.t. an external attribute.\n",
    "\n",
    "In our example, let's consider the Houses of GoT characters: what's the CD approach among the tested ones that allows to identify more \"homogeneous\" clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X_Y8V9KiB2lB"
   },
   "outputs": [],
   "source": [
    "def read_houses(filename):\n",
    "    node_to_house = {}\n",
    "    with open(filename) as f:\n",
    "        f.readline()\n",
    "        for l in f:\n",
    "            l = l.rstrip().split(\",\")\n",
    "            node_to_house[l[0]] = l[2]\n",
    "    return node_to_house\n",
    "\n",
    "def community_purity(coms, nth):\n",
    "    purities = []\n",
    "    for c in coms.communities:\n",
    "        houses = []\n",
    "        for node in c:\n",
    "            if node in nth:\n",
    "                houses.append(nth[node])\n",
    "        \n",
    "        cnt = Counter(houses)\n",
    "        purity = max(cnt.values())/sum(cnt.values())\n",
    "        purities.append(purity)\n",
    "    return purities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CJ0xjQaKB2lB"
   },
   "outputs": [],
   "source": [
    "# Game of Thrones Houses\n",
    "season = 1\n",
    "nth = read_houses(f'asioaf/got-s{season}-nodes_ext.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sP1Q5zhaB2lB"
   },
   "outputs": [],
   "source": [
    "leiden_purities = community_purity(leiden_coms, nth)\n",
    "leiden_purities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TWZTQBUuB2lB"
   },
   "outputs": [],
   "source": [
    "np.mean(leiden_purities), np.std(leiden_purities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7tarbRe3B2lC"
   },
   "outputs": [],
   "source": [
    "lp_purities = community_purity(lp_coms, nth)\n",
    "lp_purities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hDOuzwpEB2lC"
   },
   "outputs": [],
   "source": [
    "np.mean(lp_purities), np.std(lp_purities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EI80uu_sTt0f"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Chapter_5_-_Community_Discovery.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:hesplora]",
   "language": "python",
   "name": "hesplora"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
