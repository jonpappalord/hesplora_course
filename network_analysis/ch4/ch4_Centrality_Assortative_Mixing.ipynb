{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfwlZwOZ8z95"
   },
   "source": [
    "<span>\n",
    "<b>Python version:</b>  >=3.7<br/>\n",
    "<b>Networkx version:</b>  >=2.3<br/>\n",
    "<b>Last update:</b> 25/11/2021\n",
    "</span>\n",
    "\n",
    "<a id='top'></a>\n",
    "# *Chapter 4: Centrality & Assortative Mixing*\n",
    "\n",
    "In this notebook are introduced basilar analysis to cover node centrality and assortative mixing.\n",
    "\n",
    "**Note:** this notebook is purposely not 100% comprehensive, it only discusses the basic things you need to get started. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a73jUXzg8z97"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import warnings\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TxFQioVB8z97"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TXSgyu_L8z98"
   },
   "outputs": [],
   "source": [
    "def read_net(filename):\n",
    "    g = nx.Graph()\n",
    "    with open(filename) as f:\n",
    "        f.readline()\n",
    "        for l in f:\n",
    "            l = l.split(\",\")\n",
    "            g.add_edge(l[0], l[1])\n",
    "    return g\n",
    "\n",
    "# Game of Thrones data\n",
    "season = 6\n",
    "g = read_net(f'asioaf/got-s{season}-edges.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n7yZD9LbekBn"
   },
   "outputs": [],
   "source": [
    "pd.read_csv(f'asioaf/got-s{season}-nodes_ext.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "928WNid0ejUq"
   },
   "outputs": [],
   "source": [
    "houses = {}\n",
    "with open(f'asioaf/got-s{season}-nodes_ext.csv') as f:\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        node, _, house = l.rstrip().split(\",\")\n",
    "        g.add_node(node, house=house)\n",
    "\n",
    "# node position for plotting\n",
    "pos = nx.spring_layout(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8e82dgtJ8z98"
   },
   "outputs": [],
   "source": [
    "# Support function to plot networks (only small graphs)\n",
    "def draw_net(G, pos, measures, measure_name):\n",
    "    \n",
    "    plt.figure(figsize=(20,20))\n",
    "    nodes = nx.draw_networkx_nodes(G, pos, node_size=250, cmap=plt.cm.plasma, \n",
    "                                   node_color=list(measures.values()),\n",
    "                                   nodelist=measures.keys())\n",
    "    nodes.set_norm(mcolors.SymLogNorm(linthresh=0.01, linscale=1, base=10))\n",
    "    labels = nx.draw_networkx_labels(G, pos)\n",
    "    edges = nx.draw_networkx_edges(G, pos, alpha=0.2)\n",
    "    \n",
    "    plt.title(measure_name)\n",
    "    plt.colorbar(nodes)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWaGt7R18z99"
   },
   "source": [
    "## Centrality measures\n",
    "\n",
    "We can measure nodes importance using so-called centrality.\n",
    "\n",
    "**Bad term:** \n",
    "- nothing to do with being central in general\n",
    "\n",
    "**Usage:**\n",
    "- Some centralities have straightforward interpretation\n",
    "- Centralities can be used as node features for machine learning on graph\n",
    "\n",
    "\n",
    "Node centrality measures can be easily computed in python using ``networkx`` as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70wxjD0b8z9-"
   },
   "source": [
    "### Degree Centrality\n",
    "\n",
    "How many neighbors does a node have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XdEx-JmA8z9-"
   },
   "outputs": [],
   "source": [
    "degrees = dict(g.degree()) # compute the degree of a set of nodes (if specified)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zs6vzF898z9_"
   },
   "outputs": [],
   "source": [
    "ranks = [(k, v) for k, v in sorted(degrees.items(), key=lambda item: -item[1])]\n",
    "ranks[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "54SUKLGr8z-A"
   },
   "outputs": [],
   "source": [
    "draw_net(g, pos, degrees, 'Degree Centrality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8wNhvDO8z-A"
   },
   "source": [
    "### Closeness Centrality\n",
    "\n",
    "**Farness:** average of length of shortest paths to all other nodes\n",
    "\n",
    "**Closeness:** inverse of the Farness  (normalized by number of nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rcTj0uzQ8z-B"
   },
   "outputs": [],
   "source": [
    "closeness = nx.closeness_centrality(g) # compute the closeness centraliry of all nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZLP_JJTr8z-B"
   },
   "outputs": [],
   "source": [
    "ranks = [(k, v) for k, v in sorted(closeness.items(), key=lambda item: -item[1])]\n",
    "ranks[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JE4GobvL8z-B"
   },
   "outputs": [],
   "source": [
    "draw_net(g, pos, closeness, 'Closeness Centrality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XXCpMQZt8z-C"
   },
   "source": [
    "### Betweenness Centrality\n",
    "\n",
    "Number of shortest paths that go through  a node.\n",
    "\n",
    "**Assumption:** important vertices are bridges over which information flows\n",
    "\n",
    "**Practically:** if information spreads via shortest paths, important nodes are found on many shortest paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HDWkr-yV8z-C"
   },
   "outputs": [],
   "source": [
    "betweenness = nx.betweenness_centrality(g) # compute the betweenness centraliry of all nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c59I36wr8z-C"
   },
   "outputs": [],
   "source": [
    "ranks = [(k, v) for k, v in sorted(betweenness.items(), key=lambda item: -item[1])]\n",
    "ranks[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dUtVg0OV8z-C"
   },
   "outputs": [],
   "source": [
    "draw_net(g, pos, betweenness, 'Betweenness Centrality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfG45Dti8z-D"
   },
   "source": [
    "### Harmonic Centrality\n",
    "\n",
    "Harmonic mean of the geodesic (shorted paths) distances from a given node to all others.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E99-NRYA8z-D"
   },
   "outputs": [],
   "source": [
    "harmonic = nx.harmonic_centrality(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4PRObcBo8z-D"
   },
   "outputs": [],
   "source": [
    "ranks = [(k, v) for k, v in sorted(harmonic.items(), key=lambda item: -item[1])]\n",
    "ranks[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31s-XUMR8z-D"
   },
   "outputs": [],
   "source": [
    "draw_net(g, pos, harmonic, 'Harmonic Centrality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khGTtUGe8z-E"
   },
   "source": [
    "### PageRank \n",
    "\n",
    "**Main idea:** The PageRank computation can be interpreted as a Random Walk process with restart\n",
    "\n",
    "Probability that the RW will be in node i next step depends only on the current node j and the transition probability\n",
    " j ➝ i determined by the stochastic matrix\n",
    "- Consequently this is a first-order Markov process\n",
    "- Stationary probabilities (i.e., when walk length tends towards ∞ ) of the RW to be in node i gives the PageRank of the node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xUC3t64A8z-E"
   },
   "outputs": [],
   "source": [
    "pagerank = nx.pagerank(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OJJmThVb8z-E"
   },
   "outputs": [],
   "source": [
    "ranks = [(k, v) for k, v in sorted(pagerank.items(), key=lambda item: -item[1])]\n",
    "ranks[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xdfhwDqE8z-E"
   },
   "outputs": [],
   "source": [
    "draw_net(g, pos, pagerank, 'PageRank Centrality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3HHhb9C8z-E"
   },
   "source": [
    "### Eigenvector Centrality\n",
    "\n",
    "A pair of eigenvector (x) and eigenvalue (λ) is defined by the relation:\n",
    "\n",
    "    Ax = λx\n",
    "\n",
    "- x is a vector of size N that can be interpreted as the nodes scores\n",
    "- Ax yield a new vector of the same size which corresponds for each node to the sum of the received scores from its neighbors\n",
    "- the equality implies that the new scores are proportional to the previous ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wMbKrIpf8z-F"
   },
   "outputs": [],
   "source": [
    "eigen = nx.eigenvector_centrality(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QJaqBQP68z-F"
   },
   "outputs": [],
   "source": [
    "ranks = [(k, v) for k, v in sorted(eigen.items(), key=lambda item: -item[1])]\n",
    "ranks[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nk-KsW-I8z-F"
   },
   "outputs": [],
   "source": [
    "draw_net(g, pos, eigen, 'Eigenvector Centrality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIKQxftcfDzC"
   },
   "source": [
    "## Exercises\n",
    "- Compute the centralities for season 7. Who is the most central character? Do the centralities measures agree?\n",
    "- What about season 8?\n",
    "- Make a line chart visualizing the centralities of some characters over the seasons. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_dwEu-E8z-F"
   },
   "source": [
    "## Assortative Mixing\n",
    "\n",
    "**Homophily** Property of (social) networks that nodes of the same attitude tends to be connected with\n",
    "a higher probability than expected\n",
    "\n",
    "It appears as correlation between vertex properties of x(i) and x(j) if (i,j) ∈ E\n",
    "\n",
    "\n",
    "**Disassortative mixing:**\n",
    "Contrary of homophily: dissimilar nodes tend to be connected \n",
    "(e.g., sexual networks, predator-prey)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZiS5plaw8z-F"
   },
   "source": [
    "### Network wide (global) Assortativity measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8a_PWdb8z-F"
   },
   "source": [
    "#### Newman's Assortativity\n",
    "\n",
    "Quantify homophily while scalar node properties are involved (e.g., degree)\n",
    "\n",
    "*Degree assortative*\n",
    "- Nodes tends to connect homogeneously w.r.t. their degree (e.g., hubs with hubs)\n",
    "\n",
    "*Degree disassortative*\n",
    "- Nodes tends to connect in a star-like topology\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FTz_m9838z-G"
   },
   "outputs": [],
   "source": [
    "nx.degree_assortativity_coefficient(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-IqK8qD8z-G"
   },
   "source": [
    "#### KNNK\n",
    "\n",
    "*What's the expected neighbors' degree of a node given its degree?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7x0bV4028z-G"
   },
   "outputs": [],
   "source": [
    "knn = nx.k_nearest_neighbors(g) #calculate the average nearest neighbor degree of nodes with degree k.\n",
    "knn = dict(sorted(knn.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bWZErkCN8z-G"
   },
   "outputs": [],
   "source": [
    "plt.plot(list(knn.keys()), list(knn.values()), '.', ms=10, alpha=0.8)\n",
    "plt.loglog()\n",
    "plt.xlabel(\"k\", fontsize=20)\n",
    "plt.ylabel(\"k_nn(k)\",fontsize=18)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqML9Mdq8z-G"
   },
   "source": [
    "#### Newman Assortativity on node properties\n",
    "\n",
    "Same as the standard Newman's assortativity but computed on semantic information attached to nodes (e.g., labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8F7Hzp0h8z-H"
   },
   "outputs": [],
   "source": [
    "nx.attribute_assortativity_coefficient(g, 'house')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mZXQ1AR-8z-M"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "Chapter_4_-_Centrality__Assortative_Mixing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:hesplora]",
   "language": "python",
   "name": "hesplora"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
